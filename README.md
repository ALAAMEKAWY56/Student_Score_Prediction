# Student_Score_Prediction
## ğŸ“Š Student Exam Score Prediction
This project focuses on predicting students' final exam scores based on various academic, behavioral, and social factors. Using Linear Regression and Polynomial Regression, we analyze and model the relationship between features like hours studied, attendance, motivation, previous scores, and more.

## ğŸ“ Dataset
Source: Student Performance Factors - Kaggle

Size: 6,607 rows Ã— 20 columns

Target Variable: Exam_Score

Key Features:

Hours_Studied, Attendance, Previous_Scores

Categorical variables: Parental_Involvement, Internet_Access, School_Type, etc.

## ğŸ¯ Project Goals
Clean and preprocess the dataset (handle missing values, encoding)

Explore relationships between features and the exam score

Train a Linear Regression model to predict Exam_Score

Evaluate the model using MSE, MAE, and RÂ² Score

Try Polynomial Regression (degree 2 & 3) as a bonus and compare performance

## ğŸ”§ Tools & Libraries
Python ğŸ

Pandas for data handling

Matplotlib and Seaborn for visualization

Scikit-learn for modeling and evaluation

## ğŸ“ˆ Key Steps
1. ğŸ“Š Exploratory Data Analysis (EDA)
Checked for missing values

Plotted distributions & relationships (histograms, scatter plots, regression lines)

Correlation analysis to select top influencing features

2. ğŸ§¹ Data Cleaning
Filled missing categorical values with the mode

Applied One-Hot Encoding to categorical features

3. ğŸ§  Model Building
Split data into training/testing sets (80/20)

Trained Linear Regression and evaluated performance

Added Polynomial Regression (degree 2 & 3) for comparison

4. ğŸ“Š Evaluation Metrics
Mean Squared Error (MSE)

Mean Absolute Error (MAE)

RÂ² Score

## ğŸ§ª Results
Model Type	RÂ² Score	Notes
Linear Regression	0.727	Performed best overall âœ…

## ğŸ“˜ Example Prediction Output
 (Actual_Exam_Score,  Predicted_Exam_Score)
                (65,                65.38)
                (71,                71.12)
               (64,               65.14)
                (66,                66.95)

ğŸš€ Future Improvements
Feature interaction analysis

Try regularization (Ridge/Lasso)

Handle outliers for more robust results

Tune polynomial features selectively (not on full encoded data)

## ğŸ“„ License
This project is for educational purposes only.

